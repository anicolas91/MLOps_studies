{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The homework looks into the YELLOW taxi records for January and february of 2023, so we will use those instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Downloading the data. \n",
    "For the january data of 2023 yellow taxis, how many columns are there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  19\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/yellow_tripdata_2023-01.parquet')\n",
    "print('Number of columns: ', len(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Computing duration\n",
    "What is the standard deviation of the trips duration in january?\n",
    "We calculate the duration of each trip in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of the trips before we downselect is: 42.59\n"
     ]
    }
   ],
   "source": [
    "df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "print(f'The standard deviation of the trips before we downselect is: {df.duration.std():.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Dropping outliers\n",
    "We will filter so that we only keep data betwen 1 and 60 mins (inclusive).\n",
    "What fraction of the recorsd are left after you dropped the outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage left after dropping outliers is 98%\n"
     ]
    }
   ],
   "source": [
    "mask = ((df.duration >=1) & (df.duration<=60))\n",
    "df = df[mask]\n",
    "total_n = len(mask)\n",
    "filtered_n = mask.sum()\n",
    "print(f'percentage left after dropping outliers is {filtered_n/total_n*100:.0f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. One hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "- Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "- Fit a dictionary vectorizer\n",
    "- Get a feature matrix from it\n",
    "   \n",
    "What's the dimensionality of this matrix (number of columns)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of columns on one hot: 515\n"
     ]
    }
   ],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID'] # pickup and dropoff location\n",
    "numerical = ['trip_distance'] # distance of trip\n",
    "\n",
    "df[categorical] = df[categorical].astype(str) # convert to strings to avoid labeling\n",
    "\n",
    "# fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "# get feature matrix\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "print(f'no of columns on one hot: {X_train.shape[1]-1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Training a model\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "- Train a plain linear regression model with default parameters\n",
    "- Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from train data is : 7.66\n"
     ]
    }
   ],
   "source": [
    "target = 'duration'\n",
    "y_train = df[target].values\n",
    "\n",
    "# fit plain linear regression model w default parameters\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "# calculate RMSE of training data\n",
    "y_pred = lr.predict(X_train)\n",
    "train_rmse = root_mean_squared_error(y_train,y_pred)\n",
    "print(f'RMSE from train data is : {train_rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Evaluating the model\n",
    "Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "What's the RMSE on validation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check now how it performs with the validation dataset. We will create a function that we can use to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename) #read data\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime # calculate duration\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60) # convert to mins\n",
    "    mask = ((df.duration >=1) & (df.duration<=60)) # select only significant data\n",
    "    df = df[mask]\n",
    "    categorical = ['PULocationID', 'DOLocationID'] # pickup and dropoff location\n",
    "    df[categorical] = df[categorical].astype(str) # convert to string/object to prevent labeling\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the validation data using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = read_dataframe('./data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the one-hotting, predicting and calculate RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from validation data is : 7.82\n"
     ]
    }
   ],
   "source": [
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts) # no need to fit sicne its done already for training data\n",
    "\n",
    "# get actual and predicted values using fitted linear regression\n",
    "y_val = df_val['duration'].values\n",
    "y_pred_val   = lr.predict(X_val)\n",
    "\n",
    "# calculate RMSE\n",
    "val_rmse   = root_mean_squared_error(y_val,y_pred_val)\n",
    "print(f'RMSE from validation data is : {val_rmse:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
