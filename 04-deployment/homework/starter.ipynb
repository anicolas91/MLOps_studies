{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c51efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4acf73a0-51b5-4663-9bb8-8eb947863e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.6\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ef880a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc3706e",
   "metadata": {},
   "source": [
    "### Setting up parametrized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9db5c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 1\n",
    "year = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2f393",
   "metadata": {},
   "source": [
    "#### Setting up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41c08294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_model(model_name='model.bin'):\n",
    "    with open(model_name, 'rb') as f_in:\n",
    "        dv, model = pickle.load(f_in)\n",
    "    return dv, model\n",
    "\n",
    "def apply_model(year=2023,month=1,model_name='model.bin'):\n",
    "    # set up filenames\n",
    "    taxi_type = 'yellow'\n",
    "    input_file = f'https://d37ci6vzurychx.cloudfront.net/trip-data/{taxi_type}_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "    output_file = f'output/{taxi_type}/{year:04d}-{month:02d}.parquet'\n",
    "\n",
    "    # read datasets\n",
    "    df = read_data(input_file)\n",
    "    dv, model = load_model(model_name)\n",
    "\n",
    "    # applying model\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    dicts = df[categorical].to_dict(orient='records')\n",
    "    X_val = dv.transform(dicts)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # set up ride id\n",
    "    df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "    # saving the results\n",
    "    save_results(df,y_pred,output_file)\n",
    "\n",
    "    return y_pred, output_file\n",
    "\n",
    "def save_results(df: pd.DataFrame,y_pred,output_file):\n",
    "    # creating the final results df\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['ride_id'] = df['ride_id']\n",
    "    df_result['prediction'] = y_pred\n",
    "    # saving as parquet file\n",
    "    create_outfolder(output_file)\n",
    "    df_result.to_parquet(\n",
    "        output_file,\n",
    "        engine='pyarrow',\n",
    "        compression=None,\n",
    "        index=False\n",
    "    )\n",
    "    return None\n",
    "\n",
    "def create_outfolder(output_file):\n",
    "    path = os.path.dirname(output_file)\n",
    "    current_directory = os.getcwd()\n",
    "    final_directory = os.path.join(current_directory, path)\n",
    "    if not os.path.exists(final_directory):\n",
    "        os.makedirs(final_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958bfa6",
   "metadata": {},
   "source": [
    "### Reading dataset and making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31beba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, output_file = apply_model(year=year,month=month,model_name='model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643f3fd",
   "metadata": {},
   "source": [
    "## Q1. Notebook\n",
    "What's the standard deviation of the predicted duration for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf532ae7-1897-428c-ba0c-875ccaf7d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the standard deviation is 6.35\n"
     ]
    }
   ],
   "source": [
    "print(f'the standard deviation is {y_pred.std():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343e4fa",
   "metadata": {},
   "source": [
    "## Q2. Preparing the output\n",
    "What is the size of the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26aba871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size in MegaBytes is 59.2\n"
     ]
    }
   ],
   "source": [
    "file_stats = os.stat(output_file)\n",
    "print(f'File Size in MegaBytes is {(file_stats.st_size/(1024*1024)):.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509cee1",
   "metadata": {},
   "source": [
    "## Q3. Creating the scoring script\n",
    "Now let's turn the notebook into a script. Which command you need to execute for that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4c649",
   "metadata": {},
   "source": [
    "```bash\n",
    "jupyter nbconvert --to script starter.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906b79b7",
   "metadata": {},
   "source": [
    "### Q4. Virtual environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bdb2a2",
   "metadata": {},
   "source": [
    "\n",
    "ow let's put everything into a virtual environment. We'll use pipenv for that.\n",
    "\n",
    "Install all the required libraries. Pay attention to the Scikit-Learn version: it should be the same as in the starter notebook.\n",
    "\n",
    "After installing the libraries, pipenv creates two files: Pipfile and Pipfile.lock. The Pipfile.lock file keeps the hashes of the dependencies we use for the virtual env.\n",
    "\n",
    "What's the first hash for the Scikit-Learn dependency?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f987315",
   "metadata": {},
   "source": [
    "We generated a pipenv environment via:\n",
    "```bash\n",
    "pipenv install scikit-learn==1.5.0 pandas --python=3.9\n",
    "```\n",
    "Which generated a `Pipfile` and a `Pipfile.lock` in this folder. Note that pickle and os are part already of 3.9 and are not needed on pipenv\n",
    "\n",
    "#### Answer\n",
    "\n",
    "The first hash for the Scikit-Learn dependency is `sha256:057b991ac64b3e75c9c04b5f9395eaf19a6179244c089afdebaad98264bff37c`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b5594",
   "metadata": {},
   "source": [
    "### Q5. Parametrize the script\n",
    "Let's now make the script configurable via CLI. We'll create two parameters: year and month.\n",
    "\n",
    "Run the script for April 2023.\n",
    "\n",
    "What's the mean predicted duration?\n",
    "\n",
    "#### Answer\n",
    "We Run the following in bash to evaluate that:\n",
    "```bash\n",
    "pipenv shell\n",
    "python starter.py 2023 4\n",
    "```\n",
    "\n",
    "For which the mean predicted duration is `14.29 minutes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97ca084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 01/2023 the mean predicted duration is 14.20 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f'For {month:02d}/{year:04d} the mean predicted duration is {y_pred.mean():.2f} minutes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ab8e8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
